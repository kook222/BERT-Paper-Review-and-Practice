# -*- coding: utf-8 -*-
import torch
import numpy as np
import pandas as pd
import os
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from datasets import load_dataset
import evaluate

# 1. ë§¥ë¶ ê°€ì†(MPS) í™•ì¸
device = torch.device("mps") if torch.backends.mps.is_available() else torch.device("cpu")
print(f"ğŸ”¥ í•™ìŠµ ì¥ì¹˜: {device}")

# 2. ë°ì´í„°ì…‹ ì¤€ë¹„ (ë„¤íŠ¸ì›Œí¬ ìš°íšŒ: ë¡œì»¬ ì €ì¥ í›„ ë¡œë”©)
print("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘... (ë¡œì»¬ íŒŒì¼ ì‚¬ìš©)")

try:
    if not os.path.exists("train.parquet"):
        print("   -> í•™ìŠµ ë°ì´í„°(train) ë‹¤ìš´ë¡œë“œ ì¤‘...")
        df_train = pd.read_parquet("https://huggingface.co/datasets/imdb/resolve/main/plain_text/train-00000-of-00001.parquet")
        df_train.to_parquet("train.parquet")
    
    if not os.path.exists("test.parquet"):
        print("   -> í‰ê°€ ë°ì´í„°(test) ë‹¤ìš´ë¡œë“œ ì¤‘...")
        df_test = pd.read_parquet("https://huggingface.co/datasets/imdb/resolve/main/plain_text/test-00000-of-00001.parquet")
        df_test.to_parquet("test.parquet")

    data_files = {"train": "train.parquet", "test": "test.parquet"}
    dataset = load_dataset("parquet", data_files=data_files)

except Exception as e:
    print(f"âŒ ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

# í•™ìŠµì€ ì „ì²´ ë‹¤ (25,000ê°œ) ì‚¬ìš©
train_dataset = dataset["train"].shuffle(seed=42) 
# í‰ê°€ëŠ” 1,000ê°œë§Œ ì‚¬ìš© (ì†ë„ í–¥ìƒ)
eval_dataset = dataset["test"].shuffle(seed=42).select(range(1000))

model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True, max_length=128)

print("âš™ï¸ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
tokenized_train = train_dataset.map(tokenize_function, batched=True)
tokenized_eval = eval_dataset.map(tokenize_function, batched=True)

# 3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)
model.to(device)

# 4. ì •í™•ë„ ê³„ì‚° í•¨ìˆ˜
metric = evaluate.load("accuracy") 

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)

# 5. í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./bert_result",
    eval_strategy="epoch",  # ìµœì‹  ë²„ì „ í˜¸í™˜ (evaluation_strategy -> eval_strategy)
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,          
    weight_decay=0.01,
    # [ì‚­ì œí•¨] use_mps_device=True (ì´ ì˜µì…˜ì€ ì´ì œ í•„ìš” ì—†ê³  ì—ëŸ¬ë¥¼ ìœ ë°œí•´ì„œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤)
    logging_dir='./logs',
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_eval,
    compute_metrics=compute_metrics,
)

# 6. [Before] í•™ìŠµ ì „ ìƒíƒœ í‰ê°€
print("\nğŸ§ [Before] í•™ìŠµ ì „ ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
init_metrics = trainer.evaluate()
print(f"   -> í•™ìŠµ ì „ ì •í™•ë„: {init_metrics['eval_accuracy']:.4f}")

# 7. [Training] í•™ìŠµ ì‹œì‘
print("\nğŸš€ [Start] í•™ìŠµ ì‹œì‘! (ì¤‘ë‹¨ëœ ê³³ë¶€í„° ì´ì–´í•˜ê¸°)")
# resume_from_checkpoint=True ì˜µì…˜ì„ ë„£ìœ¼ë©´, bert_result í´ë”ë¥¼ ë’¤ì ¸ì„œ ê°€ì¥ ìµœì‹  íŒŒì¼ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.
train_result = trainer.train(resume_from_checkpoint=True)

# 8. [History] ê·¸ë˜í”„ë¥¼ ìœ„í•´ ê¸°ë¡ ì €ì¥
history = []
history.append({'epoch': 0, 'accuracy': init_metrics['eval_accuracy']})

for log in trainer.state.log_history:
    if 'eval_accuracy' in log:
        history.append({'epoch': log['epoch'], 'accuracy': log['eval_accuracy']})

import json
with open('training_history.json', 'w') as f:
    json.dump(history, f)

print("\nâœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ê³¼ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
trainer.save_model("./bert_final_model")